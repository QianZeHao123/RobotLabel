{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c428ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pretest_data_path = \"./data/test.xlsx\"\n",
    "pretest_data = pd.read_excel(pretest_data_path)\n",
    "\n",
    "pretest_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec1de61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61b1328",
   "metadata": {},
   "source": [
    "## OpenRouter Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ecaca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.chat_models import init_chat_model\n",
    "# openai_api_key = os.getenv(\"OPENROUTER_API_KEY\")\n",
    "# openai_api_base = \"https://openrouter.ai/api/v1\"\n",
    "\n",
    "# llm_model = \"qwen/qwen3-235b-a22b:free\"\n",
    "# llm_model = \"qwen/qwen3-32b:free\"\n",
    "# model_name = \"qwen\"\n",
    "# llm_model = \"deepseek/deepseek-v3-base:free\"\n",
    "# model_name = \"deepseek\"\n",
    "# llm_model = \"microsoft/phi-4-reasoning:free\"\n",
    "# model_name = 'phi4reason'\n",
    "# llm_model = \"nousresearch/deephermes-3-mistral-24b-preview:free\"\n",
    "# model_name = \"deephermes\"\n",
    "\n",
    "# model = init_chat_model(\n",
    "#     model=llm_model,\n",
    "#     model_provider=\"openai\",\n",
    "#     openai_api_base=openai_api_base,\n",
    "#     openai_api_key=openai_api_key,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24938b61",
   "metadata": {},
   "source": [
    "## Azure OpenAI Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e559340a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "# model = AzureChatOpenAI(\n",
    "#     azure_endpoint=os.environ[\"AZURE_OPENAI_ENDPOINT\"],\n",
    "#     azure_deployment=os.environ[\"AZURE_OPENAI_DEPLOYMENT_NAME\"],\n",
    "#     openai_api_version=os.environ[\"AZURE_OPENAI_API_VERSION\"],\n",
    "#     api_key=os.environ[\"AZURE_API_KEY\"],\n",
    "# )\n",
    "\n",
    "# model_name = \"gpt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbdb4216",
   "metadata": {},
   "source": [
    "## Gemini Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974b84fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "model = init_chat_model(\n",
    "    # \"gemini-2.0-flash\",\n",
    "    \"gemini-2.5-flash-preview-04-17\",\n",
    "    model_provider=\"google_genai\",\n",
    "    api_key=os.environ[\"GEMINI_API_KEY\"],\n",
    ")\n",
    "\n",
    "model_name = 'gemini'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d8e11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def invoke_with_retry(model, messages, max_retries, retry_delay):\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            return model.invoke(messages)\n",
    "        except Exception as e:\n",
    "            print(\n",
    "                f\"Attempt {attempt + 1} failed: {e}. Retrying in {retry_delay} seconds...\"\n",
    "            )\n",
    "            time.sleep(retry_delay)\n",
    "    raise Exception(\"Max retries exceeded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e52792a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import blame_prompt, error_prompt\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "max_retries = 20\n",
    "retry_delay = 5  # seconds\n",
    "\n",
    "conversations = pretest_data[\"conversations\"]\n",
    "results = []\n",
    "\n",
    "for conv in conversations:\n",
    "    blame_messages = [\n",
    "        SystemMessage(blame_prompt),\n",
    "        HumanMessage(conv),\n",
    "    ]\n",
    "    error_messages = [\n",
    "        SystemMessage(error_prompt),\n",
    "        HumanMessage(conv),\n",
    "    ]\n",
    "    \n",
    "    blame_res = invoke_with_retry(model, blame_messages, max_retries, retry_delay)\n",
    "    error_res = invoke_with_retry(model, error_messages, max_retries, retry_delay)\n",
    "    \n",
    "    blame_flag = 1 if blame_res.content == 'True' else 0\n",
    "    error_flag = 1 if error_res.content == 'True' else 0\n",
    "    print('----------------------------------')\n",
    "    # print(\"Original Conversation:\\n\", conv, sep='')\n",
    "    print(\"Blame:\", blame_flag)\n",
    "    print(\"Error:\", error_flag)\n",
    "\n",
    "    results.append({\n",
    "        \"Conversation\": conv,\n",
    "        \"Blame\": blame_flag,\n",
    "        \"Error\": error_flag\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60371157",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "current_time = datetime.datetime.now().strftime(\"%Y_%m_%d_%H_%M\")\n",
    "df.to_csv(f'./out/llm_label_test_result_{current_time}_{model_name}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ca566a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "robotlabel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
